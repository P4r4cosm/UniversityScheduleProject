name: Schedule
services:
  redis:
    build: ./redis
    container_name: redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
      - ./logs/redis:/var/log/redis
    command: redis-server --appendonly yes

  mongodb:
    build: ./mongodb
    container_name: mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongodb:/data/db
      - ./logs/mongodb:/var/log/mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root

  neo4j:
    build: ./neo4j
    container_name: neo4j
    restart: unless-stopped
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/61323F1nigan
    volumes:
      - ./data/neo4j:/data
      - ./logs/neo4j:/logs

  elasticsearch:
    image: elasticsearch:8.17.3
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - discovery.type=single-node
      - xpack.security.enrollment.enabled=false
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
      - ./logs/elasticsearch:/usr/share/elasticsearch/logs

  postgres:
    image: debezium/postgres:16-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=mydb
      # Настройки для CDC (Change Data Capture)
      - POSTGRES_INITDB_ARGS=--data-checksums
    ports:
      - "5433:5432"
    command: >
      postgres 
      -c wal_level=logical 
      -c max_wal_senders=10 
      -c max_replication_slots=10
      -c wal_sender_timeout=0
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./logs/postgres:/var/log/postgresql
      - ./postgres-initdb:/docker-entrypoint-initdb.d

  kibana:
    image: kibana:8.17.3
    container_name: kibana
    restart: unless-stopped
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    environment:
      - node.name=kibana
      - cluster=es-docker-cluster
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

  university-schedule-gateway:
    build:
      context: . # Предполагается, что docker-compose.yml лежит в корне решения,
                 # а Dockerfile для gateway в папке 'University Schedule Gateway'
      dockerfile: University Schedule Gateway\Dockerfile
    container_name: university_schedule_gateway_app
    restart: unless-stopped
    ports:
      - "8080:8080" # Проверьте, какие порты использует ваше приложение (8080/8081 или 80/443)
      - "8081:8081" # Если используете HTTPS
    environment:
      - ConnectionStrings__DefaultConnection=Host=postgres;Port=5432;Database=mydb;Username=admin;Password=admin
      - ASPNETCORE_ENVIRONMENT=Development
      # Если ваше приложение слушает на 80/443 внутри контейнера, измените соответственно
      - ASPNETCORE_URLS=http://+:8080;
    depends_on:
      - postgres # Зависит от postgres

  university-schedule-generator:
    build:
      context: .
      dockerfile: University Schedule Generator\Dockerfile # Путь к Dockerfile для Lab1
    container_name: university_schedule_generator_app
    restart: unless-stopped
    ports:
      - "8100:8080" # Хост-порт 8100 -> контейнер-порт 8080 (HTTP)
    environment:
       # PostgreSQL
      # PostgreSQL
      - ConnectionStrings__DefaultConnection=Host=postgres;Port=5432;Database=mydb;Username=admin;Password=admin
      # Redis
      - RedisOptions__Configuration=redis:6379
      - RedisOptions__InstanceName=docker_lab1_redis_instance # Можно задать уникальное имя
      # Elasticsearch
      - ElasticsearchOptions__Uri=http://elasticsearch:9200
      # MongoDB
      - MongoDbSettings__ConnectionString=mongodb://root:root@mongodb:27017/?authSource=admin
      - MongoDbSettings__Database=lab1_mongo_db # Может быть своя БД для каждой лабы
      # Neo4j
      - Neo4jOptions__Uri=bolt://neo4j:7687
      - Neo4jOptions__Username=neo4j
      - Neo4jOptions__Password=61323F1nigan
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:8080 # Lab1 слушает HTTP на 8080 внутри контейнера
    depends_on:
      - postgres
      # - mongodb
      # - redis
      # - neo4j
      # - elasticsearch

  # --- Лабораторная работа 1 ---
  university-schedule-lab1:
    build:
      context: .
      dockerfile: University Schedule Lab1\Dockerfile # Путь к Dockerfile для Lab1
    container_name: university_schedule_lab1_app
    restart: unless-stopped
    ports:
      - "8070:8080" # Хост-порт 8070 -> контейнер-порт 8080 (HTTP)
    environment:
       # PostgreSQL
      - ConnectionStrings__DefaultConnection=Host=postgres;Port=5432;Database=mydb;Username=admin;Password=admin
      # Redis
      - RedisOptions__Configuration=redis:6379
      - RedisOptions__InstanceName=docker_lab1_redis_instance # Можно задать уникальное имя
      # Elasticsearch
      - ElasticsearchOptions__Uri=http://elasticsearch:9200
      # MongoDB
      - MongoDbSettings__ConnectionString=mongodb://root:root@mongodb:27017/?authSource=admin
      - MongoDbSettings__Database=lab1_mongo_db # Может быть своя БД для каждой лабы
      # Neo4j
      - Neo4jOptions__Uri=bolt://neo4j:7687
      - Neo4jOptions__Username=neo4j
      - Neo4jOptions__Password=61323F1nigan
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:8080 # Lab1 слушает HTTP на 8080 внутри контейнера
    depends_on:
      - postgres
      - mongodb
      - redis
      - neo4j
      - elasticsearch

  # --- Лабораторная работа 2 ---
  university-schedule-lab2:
    build:
      context: .
      dockerfile: University Schedule Lab2\Dockerfile # Путь к Dockerfile для Lab2
    container_name: university_schedule_lab2_app
    restart: unless-stopped
    ports:
      - "8060:8080" # Хост-порт 8060 -> контейнер-порт 8080 (HTTP)
    environment:
       # PostgreSQL
      - ConnectionStrings__DefaultConnection=Host=postgres;Port=5432;Database=mydb;Username=admin;Password=admin
      # Redis
      - RedisOptions__Configuration=redis:6379
      - RedisOptions__InstanceName=docker_lab2_redis_instance # Можно задать уникальное имя
      # Elasticsearch
      - ElasticsearchOptions__Uri=http://elasticsearch:9200
      # MongoDB
      - MongoDbSettings__ConnectionString=mongodb://root:root@mongodb:27017/?authSource=admin
      - MongoDbSettings__Database=lab1_mongo_db # Может быть своя БД для каждой лабы
      # Neo4j
      - Neo4jOptions__Uri=bolt://neo4j:7687
      - Neo4jOptions__Username=neo4j
      - Neo4jOptions__Password=61323F1nigan
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:8080 # Lab2 слушает HTTP на 8080 внутри контейнера
    depends_on:
      - postgres
      - mongodb
      - redis
      - neo4j
      - elasticsearch

  # --- Лабораторная работа 3 ---
  university-schedule-lab3:
    build:
      context: .
      dockerfile: University Schedule Lab3\Dockerfile # Путь к Dockerfile для Lab3
    container_name: university_schedule_lab3_app
    restart: unless-stopped
    ports:
      - "8050:8080" # Хост-порт 8050 -> контейнер-порт 8080 (HTTP)
    environment:
     # PostgreSQL
      - ConnectionStrings__DefaultConnection=Host=postgres;Port=5432;Database=mydb;Username=admin;Password=admin
      # Redis
      - RedisOptions__Configuration=redis:6379
      - RedisOptions__InstanceName=docker_lab3_redis_instance # Можно задать уникальное имя
      # Elasticsearch
      - ElasticsearchOptions__Uri=http://elasticsearch:9200
      # MongoDB
      - MongoDbSettings__ConnectionString=mongodb://root:root@mongodb:27017/?authSource=admin
      - MongoDbSettings__Database=lab1_mongo_db # Может быть своя БД для каждой лабы
      # Neo4j
      - Neo4jOptions__Uri=bolt://neo4j:7687
      - Neo4jOptions__Username=neo4j
      - Neo4jOptions__Password=61323F1nigan
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:8080 # Lab3 слушает HTTP на 8080 внутри контейнера
    depends_on:
      - postgres
      - mongodb
      - redis
      - neo4j
      - elasticsearch

  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1 # Используйте актуальные версии
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ./data/zookeeper/data:/data
      - ./data/zookeeper/datalog:/datalog

  # --- Kafka Broker ---
  broker:
    image: confluentinc/cp-kafka:7.6.1
    container_name: broker
    hostname: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"       # Для клиентов ВНУТРИ Docker сети
      - "29092:29092"     # Для клиентов ВНЕ Docker сети (например, ваш локальный Kafka клиент)
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1 # Для cp-kafka >= 5.4.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1 # Для cp-kafka >= 5.4.0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081 # Ссылка на Schema Registry
      # Добавляем явное указание на создание топиков
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - ./data/kafka/data:/var/lib/kafka/data
    restart: unless-stopped  # Добавляем автоматический перезапуск

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    container_name: schema-registry
    hostname: schema-registry
    depends_on:
      - broker
    ports:
      - "8085:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:9092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    restart: unless-stopped  # Добавляем автоматический перезапуск

  # --- Kafka Connect ---
  kafka-connect:
    build:
      context: ./kafka-connect
      dockerfile: Dockerfile
    container_name: kafka-connect
    hostname: kafka-connect
    depends_on:
      - broker
      - schema-registry
      - postgres
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      # Используем JsonConverter для совместимости
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      # Схема-регистр для Avro (опционально)
      # CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      # CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      # CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      # CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Для отладки
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_LOG4J_LOGGERS: org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR
      # Путь к плагинам
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      # Добавляем явное указание на политику переопределения
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
    volumes:
      # Том для логов
      - ./logs/kafka-connect:/var/log/kafka-connect
      # Том для конфигураций (опционально)
      - ./config/kafka-connect:/etc/kafka-connect/custom-configs
    restart: unless-stopped  # Добавляем автоматический перезапуск

  # --- Control Center ---
  control-center:
    image: confluentinc/cp-enterprise-control-center:7.6.1
    container_name: control-center
    hostname: control-center
    depends_on:
      - broker
      - schema-registry
      - kafka-connect
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'kafka-connect:8083'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021
    volumes:
      - ./data/control-center:/var/lib/confluent-control-center

  # Сервис для автоматического запуска коннекторов
  connector-setup:
    image: curlimages/curl:latest
    container_name: connector-setup
    depends_on:
      - kafka-connect
      - postgres
      - redis
      - elasticsearch
    volumes:
      - ./config/kafka-connect:/config
    restart: on-failure
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      echo \"Waiting for services to start...\"
      # Просто держим контейнер запущенным, но не выполняем настройку коннекторов
      # Настройка будет выполняться через внешние скрипты setup-connectors.bat или setup-connectors.ps1
      sleep infinity
      "